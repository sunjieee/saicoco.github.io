---
title: "ResNeXt--Aggregated Residual Transformations for Deep Neural Networks"
subheadline: ResNeXt
layout: page
date: 2016-12-27
image: /downloads/resnet/resnext.png
categories: 
- paper_reading
tag: paper
blog: true
start: true
author: karl
description: 多模态特征融合
---  

ResNeXt[^1] 是ResNet的改进版本，其设计目的是为了使得最终网络结构只需要较少参数设置，但可以获得
较好的效果: homogeneous, multi-branch是该框架的特点．而为了达到此目的，文章提出一个新的dimension
－－cardinality．在以前所见经典网络结构中，如VGG重复的简单框架加深depth,ResNet的residual连接增加
网络结构宽度，这里的cardinality则是除depth,width之外另外一个影响网络性能的因素．　　

## 传统网络结构　　


传统网络结构设计随着结构的复杂，超参变得越来越多，而这使得网络设计变得越发困难，尤其实在层数较多时．　　

* VGG[^2]的提出改变了设计网络思路，它通过简单但是有效的策略构建除了很深的networks(16, 19)：通过堆叠
相同的blocks达到深层网络的效果．  

* Inception-series网络思想：spliy-transform-merge，blocks中加入不同的kernels：blocks将输入分别分成几块，
$$1 \times 1$$的low-dimension embedding, $$3 \time 3$$, $$5 \times 5$$的transform, 还有最后的merge.  

* ResNet[^3]继承了VGG[^2]的思路，堆叠blocks的同时，加入residual连接增加网络宽度．最后达到100+的网络深度，
并在imagenet中达到state-of-the-art.  


以上的经典结构，分为两派：一派以VGG为主的简单重复堆叠blocks，另外一派则是对blocks的精妙设计，已达到较好的效果．
但是，对于精妙设计的Inception,其对于新数据需要重新调整各种参数才可达到较好效果，而VGG之类网络只需调整较少参数即可．ResNeXt就是秉承VGG/ResNets的策略，重复堆叠blocks，但与此同时，在blocks中用较为简单的方式实现split-transform-merge．　　

## ResNeXt  

![image](/downloads/resnet/1.png)
