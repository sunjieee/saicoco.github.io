---
title: "Multimodal Compact Bilinear Pooling"
layout: post
date: 2016-12-27
image: ../downloads/mcb/head.png
headerImage: true
tag: paper
blog: true
start: true
author: karl
description: 多模态特征融合
---  

### 题外话　　

不想为自己最近找借口，一个月没干啥事，看了三体，看了西部世界，看了头文字D第一季到第五季，一时之间脱离了每天写代码，看论文的节奏，其实也未尝不好，偶尔出神一下，离开一下舒适圈，对自己未尝不是一种放松。当然，老板给的任务
一直没落下，不断的看新的论文，去发现新的可做之处，无奈还是数据集的问题，我想最后应该会解决吧。进入正题！

## 正文

今天要分析的文章是看了很久的一篇，文章在image QA领域取得了较好的效果，文章提出了一种新的多模型特征融合方法，接下来我们就这种融合方法进行描述,这里不会说太多文章细节，仅作为文章创新点的一种描述，如果想了解文章细节，移步参考文献，毕竟自己理解的才是自己的。　

### 融合流程图　　
如下图所示：　　

![mcb](../downloads/mcb/head.png)  

这里可以看到，整体的融合过程分为如下几个步骤：  

* 分别提取对应模态的特征：对图片利用pre-train的CNN提取图片高层特征，对于文本则提取word-embeding,并通过lstm解码后的特征；　　

* 利用上个步骤得到的两个模态特征，分别利用Count Sketch方法进行逼近(降维)，得到降维之后的特征；  

* 将上述得到的特征分别进行FFT，将其变换至频域，并在频域作向量内积，然后将内积结果作FFT逆变换至时域空间；  

* 后续步骤，对得到的时域特征作Signed Sqrt和L2 normalize;  

* 利用得到的新特征作分类等一系列判别工作。　　  


可以看到，上述融合过程核心工作在于：Count Sketch, FFT, iFFT等，接下来我们就集中这几点进行阐述。　　

### Count Sketch  
这里的融合方法说直白点，其实就是向量的外积，而专有名词为Compact bilinear, 对于外积来说，容易生成较高维度的特征表示，如图片特征和文本特征分别为500, 500,那么在外积之后得到的特征维度为250000,如此高的维度对于之后的分类等步骤是不现实的，原因如下：　　

* 如果使用标准的one-vs-rest线性分类器(k类)，特征维度为d,那么分类模型的参数为kd,具体来说，k=1000远小于250000的，带来不仅仅是参数增多，会带来过拟合等维度灾难容易带来的后果；
* 较高维度的特征在如今大数据背景下，占用存储较大，可以简单计算一下，一个样本得到特征维度250000，如果有一百万和这样的样本(double)，则需要200G多的存储空间；　　
* 此外，在进一步利用该特征进行特征拼接，金字塔匹配等需要特征拼接的操作，会进一步的增大存储空间的占用；　　
* 对分类造成分类困难，如此高维的特征，会带来过拟合等维度灾难问题。　　

基于上述原因，需要寻找一种降低维度的方法，在与原始向量足够逼近的情况下，达到降维的效果。同时，为在end-to-end的过程中使用，此逼近方法应可以适应端到端过程。当然在mcb中，文章[^1]提出了两种方法：RM(Random Maclaurin)和TS(Tensor Sketch)，在其中选取后者。算法流程如下：　　

![ts](../downloads/mcb/ts.png)  

上图为两种逼近方法，在分析这两种方法之前，需要描述一下为何要这么做：　　

![ts](../downloads/mcb/cb.png)   

因为对于外积而言，为了避免外积结果维度过高，因此需要在外积之前做降低维度的逼近操作，于是有了上面式子(注意看约等于号)，前面的累加和的符号可以放入内积符号中，然后就得到了最后的结果，而对于外积的形式如何转换为(3)式中的形式，可以参看下图：　　

![om](../downloads/mcb/om.png)     

经过上图变换，可以将外积化简至(3)式形式。在熟悉过程之后，我们这里可以看出，寻找一种好的逼近方法是必要的，自然就有了RM,TS方法。这里着重描述TS方法。　　

TS方法的思想在于随机逼近：构造两个哈希表h, s。h使用的均匀分布，值为向量的位置索引1到d,而s中为1和-1,每次从h和s随机产生一个数，如第k次,则需要用过哈希函数h得出h(t)=k的t值,则逼近后的向量第k个位置的值为原始向量位置(t, h(t)=k)的元素至与s(t)的相乘，然后的累加和。　　

经过上述逼近，可以得到较好的低维特征，然后利用傅里叶变换的特性，将时域内外积转换为频域内的内积，降低计算复杂度。

### 如何实现end-to-end  

以上说了整个降维过程(逼近过程)，但是如何利用其作为end-to-end学习过程中的一环也是值得我们注意的。在自定义网络层的时候，必须考虑的就是该自定义操作可不可以backpropagation,如果不可以，那就是不可学习的，如SPP层。当然，我们希望自定义层可学习，这样就可以利用数据驱动的方式学习到可用的变换。　　

![bp](../downloads/mcb/bp.png)  

由于在forward过程中，h,s是保存下来的，因此在backpropagation过程中，求导是可行的。同时文章在融合之后作了典型的分类之前的典型操作:signed square, l2 normalize,以此来保证最后特征分布的平缓。

### 应用　　

接下来，主要描述文章[^2]中该方法的应用：　　

![mcb_net](../downloads/mcb/mcb_net.png)  

文章使用上述框架做image QA,文章创新之处在于将compact Bilinear用在了Multimodal,同时加入了attention,在融合后的特征做特征选择，然后在将选择之后的特征做进一步特征融合，然后做问答分类。　　

当然，该方法也可以用于其他multimodal场景，如关于video的场景分类，暴力场景的分类，唇动语音的语音识别等。

总的来说，使用外积可以获取内积等点对点操作的融合方法不能获取特征间关系，可以使得融合后特征极大的丰富，对于后续的特征提取，特征选择具有较大的选择空间，进而使得后续的分类任务不会局限与某一局部特征；使用卷积层的特征融合，相比于全局特征融合(全连接层),可以获取局部特征之间的关联，对于QA等任务有极大的好处，详细可以参看文章[^2]后续效果。　　

以上～

### 参考文献
---
[^1]: Gao Y, Beijbom O, Zhang N, et al. Compact Bilinear Pooling[J]. Computer Science, 2015.  

[^2]: Fukui A, Park D H, Yang D, et al. Multimodal Compact Bilinear Pooling for Visual Question Answering and Visual Grounding[J]. 2016.
