---
layout: page
title: Speaker Identification的思考
tag: thinking
category: thinking
comments: true
blog: true
data: 2016-10-14
---  

### 写在前面的话　　

近期一直在思考我的论文与原作者之间的差异，总觉得我的speaker-ID与作者的差那么点东西；知道后来我在一个群里回答一个关于测试集上表现不好的原因，想到
说话人识别应该是去识别who are speaking，而不是这张脸是谁，这是我一直忽视的点。　　

## 近期的一些想法　　

近期思考才发现，各种文章中提到的视频其实是图片，如果将其放于一个文件夹中即可实现视频的效果。　　

### MFCC与视频帧的对齐　　

* 看过一篇文章，对齐手法使用的是三次样条插值，即将某张图片所处视频位置进行mfcc插值，因为语音和视频采样率不一样，因此使用插值方法得到该处mfcc值。  
* 而hu文章中对齐手法，则是得到图片所处帧位置是，利用audio sample rate/fps得到一张图片对应多少语音帧，然后使用0.02s的fft窗口，一般的覆盖窗口得到
mfcc特征，这里不知道是不是巧合，文中提到每帧对应5个随机选取的mfcc特征，但是这里的sr/fps, 得到刚好是5个mfcc特征，希望是这么计算的。　　
* 关于后续的分类，近期还在做测试，这里先挖个坑，speaker-ID的测试手法有待熟悉，但应该不是仅仅分类那么简单，因为对于mfcc与image匹配的pair可以识别为说话人，那么不匹配的应该识别为
谁，还是说应该是该帧的识别结果，应该是对帧识别结果。　　

### 语音特征的设计　　

* 希望可以找到可以代替mfcc的语音特征，如果可以end2end最好。　　


### 时序关系　　

* 目前来看，在熟悉视频预测之后，可以尝试一波时序关系的引入，因为简单的cnn只针对单帧。　　

### 关于speaker identification  

下午突然来的灵感，看过文章中都是利用pre-trained的CNN去提取最后的融合特征，然后做最后的face-audio对的判断，得到哪对是真正的匹配对，即人脸和语音皆来自同一个人。看效果是可以的，但是没有考虑一下几点：  

* 利用配对好的face-aduio　pair训练得到模型，对于配对的比较有能力去区分出属于哪个人，但是没有接受不配对数据的训练，模型对这类型数据不具有很好的区分性，因此需要对这类型数据进行训练；  
* 为了上述的实现，需要引入对是否正确匹配，因此需要两个损失函数，一个作为人脸识别，一个作为是否配对的检测。　　

因此，整个网络的任务就是如下几点：　　

* 对于配对的人脸和语音，需要识别出正确的speaker，同时需要识别出是配对的人脸和语音
* 对于不配对的人脸和语音，需要识别出正确的face, 同时需要识别出不是配对的人脸和语音

idea目前就这么多，希望几个月后可以看到成果，加油～～

### 写在后面的话　　

最近坐的有点久，腰椎有点疼，昨晚运动一晚之后感觉舒服许多，看来得多运动，毕竟身体是自己的，手机这些是戒不掉的，可以通过加强与运动让自己身体不至于太差。还有，最近貌似对科研挺上进，
心里明白并不是想水论文，只是想毕业时候肚子里有干货，不想沦为论文工具或者代码工人，引以为戒！
